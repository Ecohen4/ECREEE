---
title: "Global Trends In Urban Energy Use: The Tropical Shift"
author: Elliot Cohen and Vijay Modi
date: May 2014
output:
  html_document
---
<link href="http://kevinburke.bitbucket.org/markdowncss/markdown.css" rel="stylesheet"></link>

*************
```{r global_options, results='hide'}
library(knitr)
opts_chunk$set(fig.path='Figs/', echo=FALSE, fig.width=14, fig.height=8)
options(width=85)
```

```{r initialize, results='hide', message=FALSE}
## Set working directory
setwd("/Users/elliotcohen/Dropbox/data/Electricity/CEA/Rcommands")

## read-in csv files from NRLDC html data scapring (Chris Tan and Myf March 2014)
options(stringsAsFactors=FALSE)

## Load libraries
library(knitr)    # create RMD documents
library(plyr)     # ddply...
library(reshape2) # melt...
library(ggplot2)  # plots
library(scales)   # used in ggplot()
library(xlsx)     # read excel files
library(sm)       # density plots

# load("growth.rsav")         # 5-yr average population growth in cities w. pop > 750k
# load("growth.melt.rsav")    # ""
# load("pop.rsav")            # 5-yr average population in cities w. pop > 750k
# load("pop.melt.rsav")       # ""
# load("decadal.growth.rsav") # computed decadal population growth ('50-60, ..., '10-20)
# load("decadal.growth2.rsav")# computed decadal population growth ('55-65, ..., '15-25)
```

```{r functions}
## function to create Figure/Table numbers
incCount <- function(inObj, useName) {
    nObj <- length(inObj)
    useNum <- max(inObj) + 1
    inObj <- c(inObj, useNum)
    names(inObj)[nObj + 1] <- useName
    inObj
}
figCount <- c(`_` = 0)
tableCount <- c(`_` = 0)
## Use like this:
# figCounts <- incCount(figCount, "f.randomFigure")
```

Motivation
-----------
Many of the world's **largest** and **fastest-growing** cities--from Karachi (pop. 14 million; 34.6% increase from 2000-2010) to Delhi (22m; 39.4%), Dhaka (15m, 45.2%), Jakarta (10m; 14.8%), Bangkok (8m, 29.1%), Lagos (11m; 48.2%) and Kinshasa (9m, 55.4%)--are located in South Asia and Sub-Saharan Africa with tropical to sub-tropical climates unlike those of most OECD member cities in the global North. As the tropics/sub-tropics become increasingly urban, inustrial and affluent, it is important to consider how energy demand--particularly for thermal comfort--will evolve differently in these places than it has historically across the OECD. 

To illustrate the potential for vast differences in energy demand for thermal comfort between cities in the global North and cities in the tropics/sub-tropics, consider Delhi, India.  Delhi--with its massive population and very hot climate--is an outlier compared to OECD member cities but typical of South Asia: Peak summer temperatures routinely exceed 40 deg C. (104 F.), and intense heatwaves can approach 50 deg C. (122 F.). Given the huge temperature differential between outdoor (say 104 F.) and desired indoor air temperature (say 72 F), and the thermodynamic fact that energy for cooling scales linearly with that differential, cooling a room in Delhi would require twice as much energy as cooling a room in New York where the summer temperature differential is typically half that. In addition to higher temperatures, the summer season is also much longer: in the past year, Delhi had over **six** times as many cooling-degree days as New York City (assuming a desired indoor air temperature of 72 deg F). Compounded by leaky building envelopes in developing world cities (designed for natural ventilation, not air conditiong), intense heat-island effects (typically less green space), and massive population growth, peak electricity demand in cities thourought the developing world could one day surpass that of their neighbors to the north--not only in aggregate terms because of their size, but also *per-capita* due to thermodynamics. 

Implications of Global Energy Service Provision Parity
--------------
If we consider the trajectory of developing world cities as reaching eventual parity with OECD cities, and if we think in terms of energy *service provision* rather than just BTU or KWh, then we begin to appreciate the magnitude of future energy demand (and associated resource consumption and environmental impact). This has important implications not only for regional grid planning and supply reliability, but also the global transition to renewable energy given the limitations of meeting such large and 'peaky' demand with non-dispatchable resources such as wind and solar.

Figure 1 provides a map of urbanization rates for cities worldwide with a population greater than 750,000 (UN 2011). Urbanization rates are clearly highest in South Asia and Sub-Saharan Africa. Figure 2 shows the *distribution* of population growth rates for the same set of cities, grouped by latitude (global North, Tropics and Subtropics). The expected value (e.g. central tendancy) of urbanization rates in the Tropics and Sub-Tropics is clearly distinct from that of the North.

```{r urbanization-data, cache=TRUE, results='hide'}
## Import data
## United Nations, Department of Economic and Social Affairs, Population Division
## World Urbanization Prospects: The 2011 Revision

# Average Annual Rate of Change of Urban Agglomerations with 750,000 Inhabitants or More in 2011, by Country, 1950-2025 (per cent)
growth=read.xlsx(file="/Users/elliotcohen/Dropbox/data/Urbanization/UN_2011-Growth_Rate-Cities_Over_750k.xlsx",
                 sheetName="GROWTH-RATE-CITIES",
                 as.data.frame=TRUE,header=TRUE,check.names=TRUE,
                 startRow=13)

# Population of urban agglomerations with 750,00 inhabitants or more, 1950-2025
pop=read.xlsx(file="/Users/elliotcohen/Dropbox/data/Urbanization/UN_2011_Population-Cities_Over_750k.xlsx",
              sheetName="CITIES-OVER-750K",
              as.data.frame=TRUE,header=TRUE,check.names=TRUE,
              startRow=13, endRow=646, colIndex=c(1:23))

# match city/country to continent
countries<-scan(file="/Users/elliotcohen/Dropbox/data/Urbanization/countrylist.txt",
                what="charachter", sep="\n",
                          blank.lines.skip=TRUE)

dummy<-strsplit(countries, split=" ")
continent<-laply(dummy, '[[', 1)
country.code<-laply(dummy, '[[', 4)
country.name<-laply(dummy, '[[', 5)
df<-data.frame(Country.Code=country.code, Country.Name=country.name, Continent.Abr=continent)
df$Country.Code<-as.numeric(df$Country.Code)

df$Continent<-NA
df$Continent[which(df$Continent.Abr=="AF")]<-"Africa"
df$Continent[which(df$Continent.Abr=="AS")]<-"Asia"
df$Continent[which(df$Continent.Abr=="EU")]<-"Europe"
df$Continent[which(df$Continent.Abr=="NA")]<-"North.America"
df$Continent[which(df$Continent.Abr=="SA")]<-"South.America"
df$Continent[which(df$Continent.Abr=="OC")]<-"Oceania"
df$Continent[which(df$Continent.Abr=="AN")]<-"Antarctica"

test<-merge(pop, df, by=c("Country.Code"))
test<-subset(test, select=-Continent.Abr)
test<-subset(test, select=-Country.Name)
test<-subset(test, select=-Note)
test<-subset(test, select=c(23, 1:22))
pop<-test
save(pop, file="pop.rsav")

test<-merge(growth, df, by=c("Country.Code"))
test<-subset(test, select=-Continent.Abr)
test<-subset(test, select=-Country.Name)
test<-subset(test, select=-Note)
test<-subset(test, select=c(22, 1:21))
growth<-test
save(growth, file="growth.rsav")

## get data for a couple of well known megacities...
get<-c("Karachi", "Delhi", "Dhaka", "Jakarta", "Krung Thep (Bangkok)", "Lagos", "Kinshasa")

## compute decadal growth rates
# even decades
test<-pop[, 1:7]
test$g50.60<-(pop$X1960-pop$X1950)/pop$X1950*100
test$g60.70<-(pop$X1970-pop$X1960)/pop$X1960*100
test$g70.80<-(pop$X1980-pop$X1970)/pop$X1970*100
test$g80.90<-(pop$X1990-pop$X1980)/pop$X1980*100
test$g90.00<-(pop$X2000-pop$X1990)/pop$X1990*100
test$g00.10<-(pop$X2010-pop$X2000)/pop$X2000*100
test$g10.20<-(pop$X2020-pop$X2010)/pop$X2010*100
test[test$Urban.Agglomeration %in% get, ]
growth.decadal<-test
save(growth.decadal, file="growth.decadal.rsav")

# odd decades
test<-pop[, 1:7]
test$g55.65<-(pop$X1965-pop$X1955)/pop$X1955*100
test$g65.75<-(pop$X1975-pop$X1965)/pop$X1965*100
test$g75.85<-(pop$X1985-pop$X1975)/pop$X1975*100
test$g85.95<-(pop$X1995-pop$X1985)/pop$X1985*100
test$g95.05<-(pop$X2005-pop$X1995)/pop$X1995*100
test$g05.15<-(pop$X2015-pop$X2005)/pop$X2005*100
test$g15.25<-(pop$X2025-pop$X2015)/pop$X2015*100
test[test$Urban.Agglomeration %in% get, ]
growth.decadal2<-test
save(growth.decadal2, file="growth.decadal2.rsav")

## START HERE if loading previously saved dataframes....
# load("pop.rsav")
# load("growth.rsav")

## melt for ggplot()
df1<-melt(pop, id.vars=c(1:7))
sum(is.na(df1))

## assign pretty column names
get<-levels(df1$variable)
dummy<-strsplit(get, split="X")
test<-laply(dummy, '[[', 2)
df1$variable<-factor(df1$variable, labels=test)

## check for NA's
sum(is.na(df1))          # zero NAs
df1[which(is.na(df1)), ] # zero NAs
cc<-complete.cases(df1)  # check for missing values...
sum(cc)==dim(df1)[1]     # zero missing values.

## bin growth rates by quantile
df1$bin<-cut(df1$value, breaks=quantile(df1$value), include.lowest=TRUE)
df1$bin.name<-factor(df1$bin, labels=c("1st quartile","2nd quartile","3rd quartile","4th quartile")) # assign pretty names
names(df1)[8:11]<-c("Year","Pop.","Pop.Bin","Pop.Quartile")
pop.melt<-df1

## check for NAs and complete cases
NAs<-sum(is.na(df1)); NAs           # count NA's
if (NAs>0) df1[which(is.na(df1)), ] # Show NA's, if any.
cc<-complete.cases(df1) # check for missing values...
all(cc)                 # Given a set of logical vectors, are all of the values true?

## repeat for growth data
df2<-melt(growth, id.vars=c(1:7))
get<-levels(df2$variable)
dummy<-strsplit(get, split="X")
period<-laply(dummy, '[[', 2)
period<-gsub("[.]", "-", period)

## bin growth rates by quantile
df2$variable<-factor(df2$variable, labels=period)
df2$bin<-cut(df2$value, breaks=quantile(df2$value), include.lowest=TRUE)
df2$bin.name<-factor(df2$bin, labels=c("1st quartile","2nd quartile","3rd quartile","4th quartile"))
names(df2)[8:11]<-c("Period","Growth","Growth.Bin","Growth.Quartile")
growth.melt<-df2

## save
save(pop.melt, file="pop.melt.rsav")
save(growth.melt, file="growth.melt.rsav")

# conform population data and growth rate data for a given year
dummy<-strsplit(as.character(df2$Period), split="-")  # year ending XXXX
df2$Year<-laply(dummy, "[[", 2)
str(df2)

# check for NAs and complete cases
NAs<-sum(is.na(df2)); NAs           # count NA's
if (NAs>0) df1[which(is.na(df2)), ] # Show NA's, if any.
cc<-complete.cases(df2) # check for missing values...
all(cc)                 # Given a set of logical vectors, are all of the values true?

# MERGE
cities<-merge(df1, df2, by=c("Continent", "Country.Code", "Country", "City.Code", "Urban.Agglomeration", "Latitude", "Longitude", "Year"))

# check for NAs and complete cases
check<-function(df){
  NAs<-sum(is.na(df))
  print(paste("NAs:", NAs)) # count NA's
  if (NAs>0) df1[which(is.na(df)), ] # Show NA's, if any.
  cc<-complete.cases(df)  # check for missing values...
  print(paste("Complete Cases:", all(cc)))  # Given a set of logical vectors, are all of the values true?
  }

## group by geography... (or try clustering by lat-long attributes)
tropics<-subset(cities, Latitude>=-23.45 & Latitude <=23.45)
subtropics<-subset(cities, Latitude>=-38 & Latitude <=-23.45 | Latitude>=23.45 & Latitude <=38)
north<-subset(cities, Latitude>38)

## add region attribute to cities
cities$region<-NA
t<-which(cities$Latitude >= -23.45 & cities$Latitude <= 23.45)
cities$region[t]<-"Tropics"

st<-which(cities$Latitude>= -38 & cities$Latitude < -23.45 | cities$Latitude > 23.45 & cities$Latitude <= 38)
cities$region[st]<-"Subtropics"

n<-which(cities$Latitude > 38)
cities$region[n]<-"North"
cities$region<-as.factor(cities$region)

# ## group countries by UN economic classifications
# D1<-c("Andorra", "Australia", "Bermuda", "Canada", "Iceland", "Israel", "Liechtenstein", "Monaco", "New Zealand", "Norway", "Korea (South)", "San Marino", "Singapore", "Switzerland", "Taiwan")
# 
# D2:  "Albania", "Algeria", "Anguilla", "Antigua and Barbuda", "Argentina", "Aruba", "Bahamas", "Bahrain", "Barbados", "Belize", "Bolivia", "Bosnia and Herzegovina", "Botswana", "Brazil", "British Virgin Islands", "Brunei Darussalam", "Bulgaria", "Cameroon", "Cayman Islands", "Chile", "Colombia", "Cook Islands", "Costa Rica", "Cote d'Ivoire", "Croatia", "Cuba"," Czechoslovakia (Former)", "Korea (North)", "Dominica", "Dominican Republic", "Ecuador", "Egypt", "El Salvador", "Fiji", "French Polynesia", "Gabon", "Ghana", "Grenada", "Guatemala", "Haiti", "Honduras", "Indonesia", "Iran", "Iraq", "Jamaica", "Jordan", "Kenya", "Kuwait", "Lebanon", "Libyan Arab Jamahiriya", "Malaysia", Marshall Islands, Mauritius, Mexico, Micronesia, Mongolia, Montserrat , Morocco, Namibia, Nauru, Netherlands Antilles, New Caledonia, Nicaragua, Nigeria, Occupied Palestine, Oman, Pakistan, Palau, Panama, Papua New Guinea, Paraguay, Peru, Philippines, Puerto Rico, Qatar, Romania, Saint Kitts-Nevis, Saint Lucia, Saint Vincent and the Grenadines, Saudi Arabia, Serbia and Montenegro, Seychelles, Somalia, South Africa, Sri Lanka, Sudan, Suriname, Swaziland, Syria, Macedonia, Thailand, Tonga, Trinidad and Tobago, Tunisia, Turkey, Turks and Caicos Islands, United Arab Emirates, Uruguay, Venezuela, Vietnam, Zanzibar, Zimbabwe
# 
# D3:	Afghanistan, Angola, Bangladesh, Benin, Bhutan, Burkina Faso, Burundi, Cambodia, Cape Verde, Central African Republic, Chad, Comoros, Congo (Brazzaville), Congo (Kinshasa), Djibouti, Equatorial Guinea, Eritrea, Ethiopia, Gambia, Guinea, Guinea-Bissau, Guyana, Kiribati, Laos, Lesotho, Liberia, Madagascar, Malawi, Maldives, Mali, Mauritania, Mozambique, Myanmar, Nepal, Niger, Rwanda, Samoa, Sao Tome and Principe, Senegal, Sierra Leone, Solomon Islands, Timor-Leste, Togo, Tuvalu, Uganda, Tanzania, Vanuatu, Yemen, Zambia
# 
# EU:	Austria, Belgium, Cyprus, Czech Republic, Denmark, Finland, France, Germany, Greece, Hungary, Ireland, Italy, Luxembourg, Malta, Netherlands, Poland, Portugal, Slovakia, Slovenia, Spain, Sweden, United Kingdom
# 
# FSU:	Armenia, Azerbaijan, Belarus, Estonia, Georgia, Kazakhstan, Kyrgyzstan, Latvia, Lithuania, Moldova (Republic of), Russian Federation, Tajikistan, Turkmenistan, Ukraine, USSR (Former), Uzbekistan
#
## summarize population growth by decade
d50<-which(cities$Period %in% c("1950-1955", "1955-1960"))
d60<-which(cities$Period %in% c("1960-1965", "1965-1970"))
d70<-which(cities$Period %in% c("1970-1975", "1975-1980"))
d80<-which(cities$Period %in% c("1980-1985", "1985-1990"))
d90<-which(cities$Period %in% c("1990-1995", "1995-2000"))
d00<-which(cities$Period %in% c("2000-2005", "2005-2010"))
d10<-which(cities$Period %in% c("2010-2015", "2015-2020"))
d20<-which(cities$Period %in% c("2020-2025"))
cities$decade<-NA
cities$decade[d50]<-"Fifties"
cities$decade[d60]<-"Sixties"
cities$decade[d70]<-"Seventies"
cities$decade[d80]<-"Eighties"
cities$decade[d90]<-"Nineties"
cities$decade[d00]<-"Oughts"
cities$decade[d10]<-"Twenty-Teens"
cities$decade[d20]<-"Twenty-Twenties"

# summarize population growth by epoch
e1<-which(cities$Period %in% c("1950-1955", "1955-1960", "1960-1965", "1965-1970", "1970-1975"))
e2<-which(cities$Period %in% c("1975-1980", "1980-1985", "1985-1990", "1990-1995", "1995-2000"))
e3<-which(cities$Period %in% c("2000-2005", "2005-2010", "2010-2015", "2015-2020", "2020-2025"))
cities$epoch<-NA
cities$epoch[e1]<-"1950-1975"
cities$epoch[e2]<-"1975-2000"
cities$epoch[e3]<-"2000-2025"

epochal<-ddply(cities, .(Country.Code, Country, City.Code, Urban.Agglomeration, Latitude, Longitude, epoch), summarize, End.Pop.=Pop.[5], Annual.Growth=(Pop.[5]-Pop.[1])/Pop.[1]*100/25, Period.Growth= (Pop.[5]-Pop.[1])/Pop.[1]*100)
check(epochal) # check for NAs and complete cases
epochal<-na.omit(epochal)
epochal$epoch<-as.factor(epochal$epoch)
epochal$Period.Growth.Bin<-cut(epochal$Period.Growth, breaks=quantile(epochal$Period.Growth), include.lowest=TRUE)
epochal$Period.Growth.Quartile<-factor(epochal$Period.Growth.Bin, labels=c("1st quartile","2nd quartile","3rd quartile","4th quartile"))
check(epochal) # check for NAs and complete cases
```

```{r fig.width=12, fig.height=6, echo=FALSE, cache=TRUE}
# base map
world <- map_data("world")
worldmap <- ggplot(world, aes(x=long, y=lat, group=group)) +
  geom_path()

# CURRENT Population and Urbanization Rates
ggplot() + 
  geom_path(data=world, aes(x=long, y=lat, group=group)) +
#   geom_ribbon(data=world, x=world$long, ymin=-23.45, ymax= 23.45, alpha=0.3, fill="green") +
#   geom_ribbon(data=world, x=world$long, ymin=-38, ymax=-23.45, alpha=0.3, fill="blue") +
#   geom_ribbon(data=world, x=world$long, ymin= 23.45, ymax= 38, alpha=0.3, fill="blue") +
  geom_hline(y=-23.45, linetype=2) +
  geom_hline(y= 23.45, linetype=2) +
  geom_hline(y=-38, linetype=3) +
  geom_hline(y=38, linetype=3) +
  geom_point(data=subset(cities, Period=="2010-2015"), aes(x=Longitude, y=Latitude, colour=Growth.Quartile, size=Pop./10^3)) +
  #coord_equal() +
  scale_y_continuous(breaks=(-2:2) * 30) +
  scale_x_continuous(breaks=(-4:4) * 45) +
  labs(colour = 'Urbanization Rate', size="Population (Millions)", title="Rapid Urbanization Throughout the Tropics and Sub-Tropics") +
  theme_bw() +
  scale_color_brewer(palette="Reds") +
  scale_size(range = c(2, 10))
  
# # Evolution over time
# ggplot() + 
#   geom_path(data=world, aes(x=long, y=lat, group=group)) +
#   geom_point(data=epochal, aes(x=Longitude, y=Latitude, colour=Period.Growth.Quartile, size=End.Pop./10^3)) + 
#   facet_wrap(~epoch, nrow=length(levels(epochal$epoch))) +
#   facet_wrap(~epoch) + 
#   coord_equal() +
#   scale_y_continuous(breaks=(-2:2) * 30) +
#   scale_x_continuous(breaks=(-4:4) * 45) +
#   labs(colour = 'Urbanization Rate', size="Population (Millions)") +
#   theme_bw() +
#   scale_color_brewer(palette="Reds")
#scale_size(range = c(2, 10))

## Summary table of top 20 largest cities by population
test<-subset(cities, period=="2010-2015")
test<-test[order(-test$Pop.), ]
test$Current.Pop.<-test$Pop./10^3

# give shorter names for print layout
usa<-which(test$Country=="United States of America")
test$Country[usa]<-"U.S.A"
uae<-which(test$Country=="United Arab Emirates")
test$Country[uae]<-"U.A.E"
DRC<-which(test$Country=="Democratic Republic of the Congo")
test$Country[DRC]<-"D.R.C"

megacities<-subset(test, Current.Pop.>=10, select=c("Continent","Country","Urban.Agglomeration","Current.Pop."))
rownames(megacities)<-NULL
colnames(megacities)[4]<-"Population [MM]"
print("World's Largest Cities in 2015 (Population > 10 million)")
print(megacities, digits=3)

fastcities<-test[order(-test$Growth), ]
fastcities<-subset(fastcities, select=c("Continent","Country","Urban.Agglomeration","Growth"))
rownames(fastcities)<-NULL
colnames(fastcities)[4]<-"Growth.Rate [%]"
print("World's Fastest Growing Cities (2010-2015) with a Population > 750,000")
print(fastcities[1:20,], digits=3)
```

```{r urbanization-plots, echo=FALSE, fig.width=7, fig.height=4}
## density plots
test<-subset(cities, Year==2015)
sm.density.compare(test$Growth, test$region, xlab="% Change (Annual)", xlim=quantile(test$Growth, probs=c(0.0,.99)))
title(main="Population Growth Rate of Cities, by Region")
colfill<-c(2:(2+length(levels(test$region)))) 
legend("topright", levels(test$region), fill=colfill)

## also show cooling degree days for cities in these regions..
```

```{r Temp-Dist, echo=FALSE, include=FALSE, cache=TRUE, fig.width=7, fig.height=4, fig.align='left'}
## Load list of cities from Hadley Urban Analysis
# file<-"http://www.metoffice.gov.uk/hadobs/urban/data/Station_list1.txt"
# stns<-read.fwf(file, widths=c(5,18,7,7), header = FALSE, sep = "\t", skip = 5, strip.white=TRUE)
# names(stns)<-c("WMONo", "Stn.name","Lat","Long")
# 
# ## load Hadley ISH station metadata
# load("/Users/elliotcohen/Dropbox/data/Climate/Hadley/metdata.rsav")
# metdata$USAFID<-as.factor(metdata$USAFID)
# 
# ## add region attribute to cities
# metdata$region<-NA
# t<-which(metdata$Lat >= -23.45 & metdata$Lat <= 23.45)
# metdata$region[t]<-"Tropics"
# 
# st<-which(metdata$Lat>= -38 & metdata$Lat < -23.45 | metdata$Lat > 23.45 & metdata$Lat <= 38)
# metdata$region[st]<-"Subtropics"
# 
# n<-which(metdata$Lat > 38)
# metdata$region[n]<-"North"
# 
# metdata$region<-as.factor(metdata$region)
# metdata<-subset(metdata, select=-WBAN)
# 
# ## load Hadley ISH raw data (only includes 1 zip file so far... add others!)
# load("/Users/elliotcohen/Dropbox/data/Electricity/CEA/Data/stnData.rsav")
# 
# ## remove erroneous values
# temps<-subset(stnData, select=-precip)
# temps<-subset(temps, temp > -100) # drop values below -100 deg. C
# temps<-subset(temps, temp < 200) # drop values above 200 deg. C (boiling)
# check(temps)
# temps$USAFID<-as.factor(temps$.id)
# 
# ## match metadat with observed data by USAFID
# df<-merge(temps, metdata, by="USAFID")
# 
# # ## match UN City data with Hadley ISD metadata...
# # ## use fuzzy logic...
# # get<-cities$City
# # grab<-metdata[which(metdata$City %in% get), ]
# 
# ## density plots
# sm.density.compare(df$temp, df$region, xlab="Temperature")
# title(main="Temperature Distribution by Region")
# colfill<-c(2:(2+length(levels(df$region)))) 
# legend("topleft", levels(df$region), fill=colfill)
```

Rationale
-----------------
Mid- to long-range energy demand forecasts are typically reported as annual totals and provide little insight to the distribution throughout the year. To address this shortcoming, we focus on the diurnal and seasonal distribution of energy demand and supply, which drive system cost but recieve relatively little attention in energy outlooks. This requires more and better data than is typically available to researchers. 

Examples from India
-------------------
This study presents an empirical analysis of diurnal-to-seasonal energy use patterns for 9 states in Northern India with a combined population of nearly 1/2 billion where we have data and prior experience.  This analyses described here can serve as a methodological template for future analysis in other parts of the developing world, particularly in South Asia and Sub-Saharan Africa.

### Methods and Materials
Each state is responsible for injection-load balance within its state periphery (e.g. power control area, or PCA) and coordination with the parent (regional) grid operator. Regional grid operators, in turn, are responsible for load balance within their region and coordination with the overarching national grid. This hierarchical structure offers a "natural experiment" for testing the effect of explanatory variables of interest such as climate, urbanization and income, while controlling for confounding factors such as power sector regulatory structure, pricing mechanisms, technology adoption, and technical expertise, which can be assumed to be similar for all States operating in the same regional grid.

The Northern Region Load Dispatch Center (NRLDC) is charged with injection/load balance for the entire Northern Region (NR) of India, including coordination of 9 constituent State Load Dispatch Centers (SLDCs) located in the region, and the National Load Dispatch Center (NLDC), which handles inter-regional energy exchanges to maintain overall grid frequency and stability. The NR is the largest of 5 regional power grids, supplying 273,240 GWh in 2012/13 and meeting a peak demand of 41,790 MW.

The NRLDC maintains power system data for each of the 9 constituent states and the region as a whole. The data is publically available on their website, but only for downlaod as PDF. Batch downloading and converting PDF to readable format (e.g. csv) is messy, cumbersome and prone to errors. To side-step this limitation, and to better utilize available data, a JavaScript was developed to "scrape" HTML from inside the NRLDC web browser. Post-processing and subsequent data analysis was performed in RStudio using markdown language.

Data analyzed for this study was derived from a daily report published by the NRLDC entitled "Power Supply Position in the Northern Region". The pertinent data can be summarized as follows:
* Regional Availability and Demand: Evening-Peak (MW), Off-Peak (MW), Day-Energy (GWh)  
* State Control Area Details: Generation (GWh), Drawal (GWh), Use (GWh)  
* State Demand Met: Evening-Peak (MW), Off-Peak (MW), Day-Energy (GWh)
* Stationwise Details: Installed/Declared Capacity (MW), Peak/Off-Peak/Average Sentout (MW), Schedule/Unscheduled Interchange (GWh)  
   
   
### Regional Energy Availability and Demand
First, we explore the daily demand profile of the Northern Region (NR). For clarity, we apply weekly smoothing to the daily data.
```{r, fig.width=10, fig.height=5, fig.align='left'}
load("/Users/elliotcohen/Dropbox/data/Electricity/CEA/Rcommands/NRLDC.Table1.rsav")  #named "data"

## split data by type of information.
energy<-subset(data, select=c("Date","year","month","day","week","Energy_Supplied", "Energy_Shortage"))
power<-subset(data, select=c("Date","year","month","day","week","Peak_Met", "Peak_Shortage","Peak_Requirement","OffPeak_Met", "OffPeak_Shortage", "OffPeak_Requirement"))
freq<-subset(data, select=c("Date","year","month","day","week","Peak_Hz", "OffPeak_Hz"))

## compute additional metrics
energy$Energy_Requirement=energy$Energy_Supplied+energy$Energy_Shortage

## plot daily energy timeseries
energy.melt<-melt(energy, id.vars=c("Date","year","month","day","week"))
# ggplot(subset(energy.melt, variable != "Energy_Requirement") , aes(x=Date, y=value, group=variable, fill=variable)) + geom_area() + theme_classic() + scale_y_continuous(name="GWh", expand=c(0,0)) + labs(title="Daily Energy Supply and Shortages in the NR Grid")

## weekly smoothing of daily energy data
weekly<-ddply(energy.melt, .(year, week, variable), numcolwise(mean))  
weekly$Date<-as.Date(paste(weekly$year, weekly$week, 1, sep="-"), format="%Y-%W-%w")
weekly$uniqueweek<-paste(weekly$year, weekly$week, sep="-")

## weekly breaks
breaks<-weekly$uniqueweek[seq(1,dim(weekly)[1], by=52)]

## plot weekly energy timeseries
ggplot(subset(weekly, variable != "Energy_Requirement") , aes(x=uniqueweek, y=value, group=variable, fill=variable)) + geom_area() + theme_classic() + scale_x_discrete(breaks=breaks, name="Year-week") + scale_y_continuous(name="GWh", expand=c(0,0)) + labs(title="Daily Energy Supply and Shortages in the NR Grid (Weekly Smoothing)") + theme(legend.position=c(0.1,0.1), legend.justification=c(0,0))
```
*Figure 1. Time series of energy supply and shortages in the NR grid (2011-14)*
  
**Discussion**: 
    
    
```{r, fig.width=10, fig.align='left'}
ggplot(weekly, aes(x=Date, y=value)) + geom_line() + facet_wrap(~variable, scale="free_y", nrow=3) + theme_classic() + labs(title="Comparing Seasonality of Energy Supply, Shortage and Requirment (Weekly Smoothing)") + scale_y_continuous(name="GWh")
```
*Figure 2. Comparing seasonality of energy supply, energy shortages and energy requirement for Northern India*
  
**Discussion**:  
     
    
An important first question is when do shortages arise?  From Figure 1 we may glean that they are not strictly seasonal nor confined to peak summer months when demand is highest. To confirm, we boxplot energy shortages by month and examine their relative distributions. We see that median energy shortage is highest in October and July, with July having the highest variability of any month. Median energy shortage is lowest in the winter months.  
```{r boxplots, fig.align='center'}
# monthly boxplots
boxplot(Energy_Shortage~month, data=data, main="Monthly boxplots of Daily Energy Shortages in the NR", ylab="GWh", xlab="Month", outline=FALSE) # outliers excluded
```
*Figure 3. Monthly boxplots of daily energy shortages in Northern India*  
  
**Discussion**:  
    
    
If the magnitude of energy shortfalls (e.g. energy not supplied; ENS) is not strictly seasonal, perhaps peak shortages as a fraction of peak demand, is. In other words, do certain months experience higher rates of load-shedding at peak times?   
```{r, fig.align='center'}
data$PNM<-data$Peak_Shortage/data$Peak_Requirement
boxplot(PNM~month, data=data, main="Seasonality of Peak Shedding:\nPeak-Shedding as a Fraction of Peak-Demand for the NR Grid (2011-2014)", sub="Daily Data Pooled by Month", ylab="Shortage/Demand at Peak", xlab="Month", outline=FALSE) # outliers excluded
```
*Figure 4. Seasonality of peak shedding as fraction of peak demand*  
  
**Discussion**: Similar to Figure 2, we see the greatest variance in July, but here the median is fairly stable, with peak shedding 5-10% of peak demand in all months.   
  
    
As another check, we examine energy shortages as a function of total energy supplied.  This helps answer the question: Do shortages increase as demand increases?  We would expect this to be true if capacity adequacy was the limiting factor.   
```{r, fig.align='center'}
# plot daily energy scatterplots
plot(data$Energy_Supplied, data$Energy_Shortage, ylim=quantile(data$Energy_Shortage, probs=c(0,0.95)), ylab="Energy Shortage [GWh]", xlab="Energy Supplied [GWh]", main="Energy Shortage as a Function of Total Energy Supplied")
abline(lm(data$Energy_Shortage ~ data$Energy_Supplied), col="red") # regression line (y~x) 

# ggplot(data, aes(x=Energy_Supplied, y=Energy_Shortage)) + geom_point() + stat_smooth(method=lm) + scale_y_continuous(name="Energy Shortage [GWh]") + scale_x_continuous(name="Energy Supplied [GWh]") + labs(title="Energy Shortage as a Function of Total Energy Supplied") + theme_bw()
```
*Figure 5. Scatterplot of Energy Shortage vs. Energy Supplied*  
  
**Discussion**: 
    
    
```{r timeseries, fig.align='left', fig.width=10}
# # For each date, get the week of the year it belongs to by formatting it via format() using the %U or %W format placeholders. %U treats Sunday as the first day of the week, whereas %W considers Monday to be the first day of the week. Here is an example:
# now <- as.Date(Sys.time())
# dates <- seq(now, now + 25, by = "1 day") 
# dat <- data.frame(Dates = dates, Week = format(dates, format = "%W"))
# head(dat, 10)
# # or alternatively... get the # of completed weeks (not calendar weeks)
# dweek <- as.numeric(dvec-dvec[1]) %/% 7  

### visualize time series objects 
## Select data to visualize. (e.g. energy shortages)
daily <- ts(data$Energy_Shortage, start = c(2011, 01), frequency = 365) #create time series object
weekly<-aggregate(daily, nfrequency=52, ts.eps=1, FUN=sum)             
monthly<-aggregate(daily, nfrequency=12, ts.eps=1, FUN=sum)
par(mfrow=c(3,1))
par(oma=c(0,0,2,0))             # set outter margins
par(mar=c(2,4,2,2) + 0.1)       # set plot margins
# par(mar=c(5,4,4,2) + 0.1.)    # default (bottom, left, top, right)
plot(daily, cex.lab=1.2, cex.axis=1.2)
plot(weekly, cex.lab=1.2, cex.axis=1.2)
plot(monthly, cex.lab=1.2, cex.axis=1.2)
title(main="Energy shortages [GWh] in the NR grid at varying time scales", outer=TRUE, cex.main=1.5)
```
*Figure 6. Daily energy shortages [in GWh] for the NR grid, with weekly and monthly smoothing*  
  
**Discussion**:
    
    
```{r, fig.width=10} 
## energy supplied
daily <- ts(data$Energy_Supplied, start = c(2011, 01), frequency = 365) #daily
weekly<-aggregate(daily, nfrequency=52, ts.eps=1, FUN=sum) #weekly
monthly<-aggregate(daily, nfrequency=12, ts.eps=1, FUN=sum) #monthly
par(mfrow=c(3,1))
par(oma=c(0,0,2,0))           # set outter margins
par(mar=c(2,4,2,2) + 0.1)     # set plot margins
# par(mar=c(5,4,4,2) + 0.1.)    # default (bottom, left, top, right)
plot(daily, cex.lab=1.2, cex.axis=1.2)
plot(weekly, cex.lab=1.2, cex.axis=1.2)
plot(monthly, cex.lab=1.2, cex.axis=1.2)
title(main="Energy supplied [GWh] to the NR grid at varying time scales", outer=TRUE, cex.main=1.5)
```
*Figure 7. Daily energy supply [in GWh] for the NR grid, with weekly and monthly smoothing*  
  
**Discussion**:  
    
    
```{r, fig.width=10}
## compute RNS: fraction of energy requirement not supplied
data$RNS<-data$Energy_Shortage/(data$Energy_Shortage+data$Energy_Supplied)
daily <- ts(data$RNS, start = c(2011, 01), frequency = 365) #daily
weekly<-aggregate(daily, nfrequency=52, ts.eps=1, FUN=mean) #weekly
monthly<-aggregate(daily, nfrequency=12, ts.eps=1, FUN=mean) #monthly
par(mfrow=c(3,1))
par(oma=c(0,0,4,0))           #set outter margins
par(mar=c(2,4,2,2) + 0.1)     # set plot margins
# par(mar=c(5,4,4,2) + 0.1.) # default (bottom, left, top, right)
plot(daily, cex.lab=1.2, cex.axis=1.2)
plot(weekly, cex.lab=1.2, cex.axis=1.2)
plot(monthly, cex.lab=1.2, cex.axis=1.2)
title(main="Energy Not Supplied as a Fraction of Total Requirement for the NR grid\n(Value of 0 indicates perfect reliability)", outer=TRUE, cex.main=1.5, cex.sub=1.5)
```
*Figure 8. Fraction _Energy Not Supplied_ to the NR grid, with weekly and monthly smoothing* 
**Discussion**:...  
    
```{r, fig.width=10}
## Look at difference between peak and off peak demand
daily <- ts(as.matrix(cbind(data$Peak_Requirement, data$OffPeak_Requirement)), start = c(2011, 01), frequency = 365)
weekly<-aggregate(daily, nfrequency=52, ts.eps=1, FUN=mean) #weekly
monthly<-aggregate(daily, nfrequency=12, ts.eps=1, FUN=mean) #monthly

par(mfrow=c(3,1))
par(oma=c(0,0,2,0))           #set outter margins
par(mar=c(2,4,1,2) + 0.1)     # set plot margins

plot(daily, plot.type="single", lty=c(1,2), col=c("blue","red")) 
legend("topleft", legend=c("Peak Demand","Off-Peak Demand"), col=c("blue","red"), lty=c(1,2))
plot(weekly, plot.type="single", lty=c(1,2), col=c("blue","red")) 
legend("topleft", legend=c("Peak Demand","Off-Peak Demand"), col=c("blue","red"), lty=c(1,2))
plot(monthly, plot.type="single", lty=c(1,2), col=c("blue","red")) 
legend("topleft", legend=c("Peak Demand","Off-Peak Demand"), col=c("blue","red"), lty=c(1,2))
title(main="Comparing Daily Peak vs Off-Peak Demand for the NR grid with weekly and monthly smoothing", outer=TRUE, cex.main=1.5, cex.sub=1.5)
```
*Figure 9. Comparing Daily Peak vs Off-Peak Demand for the NR grid with weekly and monthly smoothing*  
  
**Discussion**:
    